CaptionCraft is an advanced image captioning system that combines computer vision with natural language processing to generate descriptive captions for images. Using a combination of CNNs (specifically VGG16 for feature extraction) and LSTM layers, the model learns both visual and contextual features, enabling it to produce coherent and relevant captions for new images. The project preprocesses images and captions, tokenizes text, and evaluates model accuracy using BLEU scores, ensuring meaningful, high-quality captions. A visualization interface allows users to see both actual and predicted captions alongside images, providing clear insights into model performance.

This project was highly appreciated by faculty for its innovative application of deep learning in image processing and natural language generation.
